{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R (env R_env)",
      "language": "R",
      "name": "r-dku-venv-r_env"
    },
    "associatedRecipe": "compute_xcPrnvPS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740376599429
    },
    "creator": "admin",
    "createdOn": 1740376599429,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Libraries\n",
        "library(dataiku)\n",
        "library(rpart)\n",
        "library(dplyr)\n",
        "library(caret)\n",
        "library(pROC) # For AUC calculation\n",
        "library(data.table)\n",
        "library(mlflow)\n",
        "library(reticulate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "py_config()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe inputs\n",
        "df_base_train \u003c- dkuReadDataset(\"base_train\", samplingMethod\u003d\"head\", nbRows\u003d100000)\n",
        "df_base_validation \u003c- dkuReadDataset(\"base_validation\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training structural equation for wind speed\n",
        "# wind_speed \u003d f(track_min_dist, eps)\n",
        "\n",
        "base_wind_model \u003c- rpart(wind_max ~ track_min_dist,\n",
        "                       data \u003d df_base_train,\n",
        "                       method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training structural equation for rain speed\n",
        "# rain_total \u003d f(track_min_dist, eps)\n",
        "\n",
        "base_rain_model \u003c- rpart(rain_total ~ track_min_dist,\n",
        "                       data \u003d df_base_train,\n",
        "                       method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Adding the predicted parents\u0027 to the training dataset\n",
        "\n",
        "df_base_train \u003c- df_base_train %\u003e%\n",
        "  mutate(wind_max_pred \u003d predict(base_wind_model,\n",
        "                                 newdata \u003d df_base_train),\n",
        "         rain_total_pred \u003d predict(base_rain_model,\n",
        "                                   newdata \u003d df_base_train)\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# parameter tuning\n",
        "# Define a grid of hyperparameters\n",
        "cp_values \u003c- seq(0.0001, 0.05, by \u003d 0.005)\n",
        "maxdepth_values \u003c- c(3, 5, 7, 10)\n",
        "minsplit_values \u003c- c(10, 20, 30, 40)\n",
        "minbucket_values \u003c- c(5, 10, 20)\n",
        "\n",
        "# Create an empty list to store results\n",
        "results_list \u003c- list()\n",
        "\n",
        "# predicting for wind and rainfall for the validation dataset\n",
        "df_val_base_tune \u003c- df_base_validation %\u003e%\n",
        "  mutate(\n",
        "    wind_max_pred \u003d predict(\n",
        "      base_wind_model, newdata \u003d df_base_validation),\n",
        "    rain_total_pred \u003d predict(\n",
        "      base_rain_model,\n",
        "      newdata \u003d df_base_validation)\n",
        "    )\n",
        "\n",
        "# Train the model using manual grid search\n",
        "grid_id \u003c- 1  # Index for list storage\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for (cp in cp_values) {\n",
        "  for (maxdepth in maxdepth_values) {\n",
        "    for (minsplit in minsplit_values) {\n",
        "      for (minbucket in minbucket_values) {\n",
        "\n",
        "        # Train the model with specific hyperparameters\n",
        "        model \u003c- rpart(\n",
        "          damage_binary ~ wind_max_pred +\n",
        "            rain_total_pred +\n",
        "            roof_strong_wall_strong +\n",
        "            roof_strong_wall_light +\n",
        "            roof_strong_wall_salv +\n",
        "            roof_light_wall_strong +\n",
        "            roof_light_wall_light +\n",
        "            roof_light_wall_salv +\n",
        "            roof_salv_wall_strong +\n",
        "            roof_salv_wall_light +\n",
        "            roof_salv_wall_salv +\n",
        "            ls_risk_pct +\n",
        "            ss_risk_pct +\n",
        "            wind_blue_ss +\n",
        "            wind_yellow_ss +\n",
        "            wind_orange_ss +\n",
        "            wind_red_ss +\n",
        "            rain_blue_ss +\n",
        "            rain_yellow_ss +\n",
        "            rain_orange_ss +\n",
        "            rain_red_ss,\n",
        "          data \u003d df_base_train,\n",
        "          method \u003d \"class\",  # classification\n",
        "          control \u003d rpart.control(cp \u003d cp, maxdepth \u003d maxdepth,\n",
        "                                  minsplit \u003d minsplit, minbucket \u003d minbucket)\n",
        "        )\n",
        "\n",
        "        # Make probability predictions for classification\n",
        "        val_predictions \u003c- predict(model, newdata \u003d df_val_base_tune, type \u003d \"prob\")[,2]  # Probability of class 1\n",
        "\n",
        "        # Compute AUC (better for classification)\n",
        "        auc_value \u003c- auc(df_val_base_tune$damage_binary, val_predictions)\n",
        "\n",
        "        # Store results efficiently in a list\n",
        "        results_list[[grid_id]] \u003c- data.frame(cp, maxdepth, minsplit, minbucket, AUC \u003d auc_value)\n",
        "        grid_id \u003c- grid_id + 1\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "# Convert list to data frame\n",
        "results \u003c- rbindlist(results_list)\n",
        "\n",
        "# Print the best hyperparameter combination (highest AUC)\n",
        "best_params \u003c- results[which.max(results$AUC), ]\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training based on tuned parameters\n",
        "\n",
        "# Combine Training and Validation datasets for final training\n",
        "\n",
        "final_training_df  \u003c- rbind(df_base_train,\n",
        "                           df_val_base_tune)\n",
        "\n",
        "\n",
        "damage_fit_class_min \u003c- rpart(damage_binary ~ wind_max_pred +\n",
        "                              rain_total_pred +\n",
        "                              roof_strong_wall_strong +\n",
        "                              roof_strong_wall_light +\n",
        "                              roof_strong_wall_salv +\n",
        "                              roof_light_wall_strong +\n",
        "                              roof_light_wall_light +\n",
        "                              roof_light_wall_salv +\n",
        "                              roof_salv_wall_strong +\n",
        "                              roof_salv_wall_light +\n",
        "                              roof_salv_wall_salv +\n",
        "                              ls_risk_pct +\n",
        "                              ss_risk_pct +\n",
        "                              wind_blue_ss +\n",
        "                              wind_yellow_ss +\n",
        "                              wind_orange_ss +\n",
        "                              wind_red_ss +\n",
        "                              rain_blue_ss +\n",
        "                              rain_yellow_ss +\n",
        "                              rain_orange_ss +\n",
        "                              rain_red_ss,\n",
        "                              method \u003d \"class\",\n",
        "                              control \u003d rpart.control(cp \u003d best_params$cp,\n",
        "                                                      maxdepth \u003d best_params$maxdepth,\n",
        "                                                      minsplit \u003d best_params$minsplit,\n",
        "                                                      minbucket \u003d best_params$minbucket),\n",
        "                              data \u003d final_training_df\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Sanity Check\n",
        "# testing on the training datasets (training + validation)\n",
        "\n",
        "## Outcome prediction on the final_training_df dataset\n",
        "## default function predict returns class probabilities (has two columns)\n",
        "y_pred_probs \u003c- predict(damage_fit_class_min,\n",
        "                  newdata \u003d final_training_df)\n",
        "\n",
        "## extracting probability that y_pred \u003d\u003d 1\n",
        "y_pred_prob_1 \u003c- y_pred_probs[ ,2]\n",
        "\n",
        "## assigning final class based on threshold\n",
        "y_pred \u003c- ifelse(y_pred_prob_1 \u003e 0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# using table function\n",
        "conf_matrix \u003c- table(predicted \u003d y_pred,\n",
        "                     actual \u003d final_training_df$damage_binary\n",
        "                     )\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "accuracy \u003c- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
        "\n",
        "cat(\"test-set accuracy of minimal SCM model:\", accuracy, sep \u003d \" \")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "#\u0027 Loggint the model and parameter using MLflow\n",
        "# Start MLflow Run\n",
        "\n",
        "# Configure reticulate to use the Python environment with MLflow\n",
        "# use_python(Sys.which(\"python3\"))\n",
        "\n",
        "# mlflow \u003c- import(\"mlflow\")\n",
        "\n",
        "# Assuming \u0027damage_fit_class_min\u0027 is your R model object\n",
        "# Load your R model (saved as .rds file)\n",
        "# model \u003c- readRDS(\"path/to/your/model.rds\")\n",
        "\n",
        "# Assuming you have some hyperparameters for the model (example)\n",
        "#hyperparameters \u003c- list(\n",
        "#  cp \u003d best_params$cp,\n",
        "#  maxdepth \u003d best_params$maxdepth,\n",
        "#  minsplit \u003d best_params$minsplit,\n",
        "#  minbucket \u003d best_params$minbucket\n",
        "#)\n",
        "\n",
        "# Assuming \u0027accuracy\u0027 is the accuracy score of your model (example)\n",
        "#accuracy \u003c- 0.85  # Replace with your actual accuracy score\n",
        "\n",
        "# Function to log the R model with hyperparameters and accuracy\n",
        "#log_model_to_mlflow \u003c- function(model, accuracy, hyperparameters) {\n",
        "    # Start an MLflow run\n",
        "#  mlflow$start_run()\n",
        "\n",
        "  # Log hyperparameters\n",
        "#  mlflow$log_param(\"cp\", hyperparameters$cp)\n",
        "#  mlflow$log_param(\"maxdepth\", hyperparameters$maxdepth)\n",
        "#  mlflow$log_param(\"minsplit\", hyperparameters$minsplit)\n",
        "#  mlflow$log_param(\"minbucket\", hyperparameters$minbucket)\n",
        "\n",
        "\n",
        "  # Log model accuracy\n",
        "#  mlflow$log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "  # Save the model to the managed folder path in Dataiku DSS\n",
        "#  managed_folder_path \u003c- dkuManagedFolderPath(\"xcPrnvPS\")\n",
        "#  model_path \u003c- paste0(managed_folder_path, \"/base_clas_min_model.rds\")\n",
        "\n",
        "  # Save the model as an RDS file in the managed folder\n",
        "#  saveRDS(model, file \u003d model_path)\n",
        "\n",
        "  # Log the saved model as an artifact in MLflow\n",
        "#  mlflow$log_artifact(model_path)\n",
        "\n",
        "    # End the MLflow run\n",
        "#  mlflow$end_run()\n",
        "#}\n",
        "\n",
        "# Log the model, accuracy, and hyperparameters to MLflow\n",
        "#log_model_to_mlflow(damage_fit_class_min, accuracy, hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe outputs\n",
        "managed_folder_path \u003c- dkuManagedFolderPath(\"xcPrnvPS\")\n",
        "\n",
        "saveRDS(damage_fit_class_min, file \u003d paste0(managed_folder_path, \"/base_clas_min_model.rds\"))\n",
        "\n",
        "saveRDS(base_wind_model, file \u003d paste0(managed_folder_path, \"/base_wind_model.rds\"))\n",
        "\n",
        "saveRDS(base_rain_model, file \u003d paste0(managed_folder_path, \"/base_rain_model.rds\"))"
      ]
    }
  ]
}