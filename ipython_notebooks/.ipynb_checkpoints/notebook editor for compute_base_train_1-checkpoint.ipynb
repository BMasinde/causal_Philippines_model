{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "associatedRecipe": "train_test_val_split",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740066610508
    },
    "creator": "admin",
    "createdOn": 1740066610508,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train, Test, and Validation Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do a 60/20/20 split to create the datasets. Because we are going to use the hurdle method for predictions we split the modeling data into two categories: base and truncated. No additional processing (filtering) is required to create \"base_\" datasets. To create \"truncated_\" datasets we filter the modeling data by outcome variable (damage_perc \u003e\u003d 10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Libraries\n",
        "library(dataiku)\n",
        "library(dplyr)\n",
        "\n",
        "# Recipe inputs\n",
        "modeling_data \u003c- dkuReadDataset(\"modeling_data\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# splits for base_ datasets\n",
        "\n",
        "# number of rows in modeling_data\n",
        "n \u003c- nrow(modeling_data)\n",
        "\n",
        "# Seeding for reproducibility\n",
        "set.seed(12345)\n",
        "\n",
        "# Generate random indices for 60% training set\n",
        "base_train_id \u003c- sample(1:n, floor(n * 0.6), replace \u003d FALSE)\n",
        "\n",
        "# Remaining indices after training selection\n",
        "base_remaining_id \u003c- setdiff(1:n, base_train_id)\n",
        "\n",
        "# Split remaining 40% into 20% validation and 20% test\n",
        "base_val_id \u003c- sample(base_remaining_id, floor(n * 0.2))\n",
        "\n",
        "base_test_id \u003c- setdiff(base_remaining_id, base_val_id)  # The rest goes to test\n",
        "\n",
        "\n",
        "# Compute recipe outputs for base_ datasets\n",
        "base_train \u003c- modeling_data[base_train_id, ] # Compute a data frame for the output to write into base_train\n",
        "\n",
        "base_test \u003c- modeling_data[base_test_id, ] # Compute a data frame for the output to write into base_test\n",
        "\n",
        "base_validation \u003c- modeling_data[base_val_id, ] # Compute a data frame for the output to write into base_validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# splits for truncated_ datasets\n",
        "\n",
        "# Filtering modeling data by column damage_perc \u003e\u003d 10\n",
        "truncated_data \u003c- modeling_data %\u003e%\n",
        "  filter(damage_perc \u003e\u003d 10.0)\n",
        "\n",
        "# Reset row ID\u0027s\n",
        "rownames(truncated_data) \u003c- 1:nrow(truncated_data)\n",
        "\n",
        "# number of observations with damage \u003e 10\n",
        "n_trunc \u003c- nrow(truncated_data)\n",
        "\n",
        "# Sample 60% for training\n",
        "trunc_train_id \u003c- sample(1:n_trunc, floor(n_trunc * 0.6), replace \u003d FALSE)\n",
        "\n",
        "# Get remaining 40% indices\n",
        "trunc_remaining_id \u003c- setdiff(1:n_trunc, trunc_train_id)\n",
        "\n",
        "# Calculate correct split for validation and test (each should be 50% of the remaining)\n",
        "n_remaining \u003c- length(trunc_remaining_id)\n",
        "val_size \u003c- floor(n_remaining * 0.5)  # 50% of remaining\n",
        "\n",
        "# Sample validation set from remaining\n",
        "trunc_val_id \u003c- sample(trunc_remaining_id, val_size, replace \u003d FALSE)\n",
        "\n",
        "## The rest (remaining 20%) goes to test\n",
        "trunc_test_id \u003c- setdiff(trunc_remaining_id, trunc_val_id)\n",
        "\n",
        "\n",
        "# Compute recipe outputs for truncated_ datasets\n",
        "truncated_train \u003c- truncated_data[trunc_train_id, ] # Compute a data frame for the output to write into truncated_train\n",
        "\n",
        "truncated_validation \u003c- truncated_data[trunc_val_id, ] # Compute a data frame for the output to write into truncated_validation\n",
        "\n",
        "truncated_test \u003c- truncated_data[trunc_test_id, ] # Compute a data frame for the output to write into truncated_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe outputs\n",
        "dkuWriteDataset(base_train,\"base_train\")\n",
        "dkuWriteDataset(base_test,\"base_test\")\n",
        "dkuWriteDataset(base_validation,\"base_validation\")\n",
        "dkuWriteDataset(truncated_train,\"truncated_train\")\n",
        "dkuWriteDataset(truncated_validation,\"truncated_validation\")\n",
        "dkuWriteDataset(truncated_test,\"truncated_test\")"
      ]
    }
  ]
}