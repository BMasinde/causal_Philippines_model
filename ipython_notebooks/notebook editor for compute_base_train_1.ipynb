{
  "metadata": {
    "kernelspec": {
      "name": "r-dku-venv-r_4_4_1",
      "display_name": "R (env R_4_4_1)",
      "language": "R"
    },
    "hide_input": false,
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "4.4.1"
    },
    "tags": [
      "recipe-editor"
    ],
    "associatedRecipe": "compute_base_train",
    "customFields": {},
    "creator": "admin",
    "createdOn": 1740066610508,
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train, Test, and Validation Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do a 60/20/20 split to create the datasets. Because we are going to use the hurdle method for predictions we split the modeling data into two categories: base and truncated. No additional processing (filtering) is required to create \"base_\" datasets. To create \"truncated_\" datasets we filter the modeling data by outcome variable (damage_perc \u003e\u003d 10). "
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "library(dataiku)\n\n# Recipe inputs\nmodeling_data \u003c- dkuReadDataset(\"modeling_data\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# splits for base_ datasets\n\n# number of rows in modeling_data\nn \u003c- nrow(modeling_data)\n\n# Seeding for reproducibility\nset.seed(12345)\n\n# Generate random indices for 60% training set\nbase_train_id \u003c- sample(1:n, floor(n * 0.6))\n\n# Remaining indices after training selection\nbase_remaining_id \u003c- setdiff(1:n, base_train_id)\n\n# Split remaining 40% into 20% validation and 20% test\nbase_val_id \u003c- sample(base_remaining_id, floor(n * 0.2))\n\nbase_test_id \u003c- setdiff(base_remaining_id, base_val_id)  # The rest goes to test\n\n\n# Compute recipe outputs for base_ datasets\nbase_train \u003c- modeling_data[base_train_id] # Compute a data frame for the output to write into base_train\n\nbase_test \u003c- modeling_data[base_test_id] # Compute a data frame for the output to write into base_test\n\nbase_validation \u003c- modeling_data[base_val_id] # Compute a data frame for the output to write into base_validation"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# splits for truncated_ datasets\n\ndf_cleaned_high \u003c- df_cleaned %\u003e%\n  filter(DAM_perc_dmg \u003e\u003d 10)\n\n## reset row ID\u0027s\nrownames(df_cleaned_high) \u003c- 1:nrow(df_cleaned_high)\n\n## number of observations with damage \u003e 10\nn_high \u003c- nrow(df_cleaned_high)\n\n## use 60, 40 split\ntrain_id_high \u003c- sample(1:n_high, \n                  floor(n_high*0.6)\n                  )\n\n## Get the remaining 40% indices\nremaining_id_high \u003c- setdiff(1:n_high, train_id_high)\n\n# Randomly select 50% of the remaining (which is 20% of the total) for validation\nval_id_high \u003c- sample(remaining_id_high, floor(n_high * 0.2))\n\n## The rest (remaining 20%) goes to test\ntest_id_high \u003c- setdiff(remaining_id_high, val_id_high)\n\n## Create train, validation, and test datasets\ndf_high_train \u003c- df_cleaned_high[train_id_high, ]\ndf_high_val \u003c- df_cleaned_high[val_id_high, ]\ndf_high_test \u003c- df_cleaned_high[test_id_high, ]\n\n# Compute recipe outputs for truncated_ datasets\ntruncated_train \u003c- replace_me # Compute a data frame for the output to write into truncated_train\ntruncated_validation \u003c- replace_me # Compute a data frame for the output to write into truncated_validation\ntruncated_test \u003c- replace_me # Compute a data frame for the output to write into truncated_test"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe outputs\ndkuWriteDataset(base_train,\"base_train\")\ndkuWriteDataset(base_test,\"base_test\")\ndkuWriteDataset(base_validation,\"base_validation\")\ndkuWriteDataset(truncated_train,\"truncated_train\")\ndkuWriteDataset(truncated_validation,\"truncated_validation\")\ndkuWriteDataset(truncated_test,\"truncated_test\")"
      ],
      "outputs": []
    }
  ]
}