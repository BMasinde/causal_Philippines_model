{
  "metadata": {
    "kernelspec": {
      "name": "r-dku-venv-r_env",
      "display_name": "R (env R_env)",
      "language": "R"
    },
    "hide_input": false,
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "4.4.1"
    },
    "createdOn": 1740392855582,
    "associatedRecipe": "compute_ZijSaAqQ",
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740392855582
    },
    "customFields": {},
    "creator": "admin",
    "tags": [
      "recipe-editor"
    ],
    "dkuGit": {
      "lastInteraction": 0
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Libraries\nlibrary(dataiku)\nlibrary(rpart)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(data.table)\nlibrary(mlflow)\nlibrary(reticulate)\nlibrary(Metrics)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe inputs\nbase_train \u003c- dkuReadDataset(\"base_train\", samplingMethod\u003d\"head\", nbRows\u003d100000)\nbase_validation \u003c- dkuReadDataset(\"base_validation\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Combining train and validation datasets to one\n# Because we are going to use CV to train the models later\n# naming it df_base_train2 to remain consistent with df naming\ndf_base_train2  \u003c- rbind(df_base_train, df_base_validation)\n\ncat(\"number of rows in combined train data:\", nrow(df_base_train2), sep \u003d \" \")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training track_min_dist ~ island_groups\n# we will need to also include island_groups\n# in the final outcome prediction model to adjust for the confounding\n\nbase_track_model  \u003c- rpart(track_min_dist  ~ island_groups,\n                          data \u003d df_base_train2,\n                          method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training structural equation for wind speed\n# wind_speed \u003d f(track_min_dist, eps)\n\nbase_wind_model \u003c- rpart(wind_max ~ track_min_dist,\n                       data \u003d df_base_train2,\n                       method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training structural equation for rain speed\n# rain_total \u003d f(track_min_dist, eps)\n\nbase_rain_model \u003c- rpart(rain_total ~ track_min_dist,\n                       data \u003d df_base_train2,\n                       method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Building typologies are determined by region\nbase_roof_strong_wall_strong_model  \u003c- rpart(roof_strong_wall_strong  ~ island_groups, \n                                             data \u003d df_base_train2,\n                                            method \u003d \"anova\")\n\nbase_roof_strong_wall_light_model  \u003c- rpart(roof_strong_wall_light ~ island_groups,\n                                           data \u003d df_base_train2,\n                                           method \u003d \"anova\")\n\nbase_roof_strong_wall_salv_model  \u003c- rpart(roof_strong_wall_salv ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\nbase_roof_light_wall_strong_model  \u003c- rpart(roof_light_wall_strong ~ island_groups,\n                                           data \u003d df_base_train2,\n                                           method \u003d \"anova\")\nbase_roof_light_wall_light_model  \u003c- rpart(roof_light_wall_light ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\nbase_roof_light_wall_salv_model  \u003c- rpart(roof_light_wall_salv ~ island_groups,\n                                         data \u003d df_base_train2,\n                                         method \u003d \"anova\")\n\nbase_roof_salv_wall_strong_model  \u003c- rpart(roof_salv_wall_strong ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\n\nbase_roof_salv_wall_light_model  \u003c- rpart(roof_salv_wall_light ~ island_groups,\n                                  data \u003d df_base_train2,\n                                  method \u003d \"anova\")\n\nbase_roof_salv_wall_salv_model  \u003c- rpart(roof_salv_wall_salv ~ island_groups,\n                                  data \u003d df_base_train2,\n                                  method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# # Adding the predicted parents\u0027 to the training dataset\n\n# df_base_train \u003c- base_train %\u003e%\n#   mutate(wind_max_pred \u003d predict(base_wind_model,\n#                                  newdata \u003d df_base_train2),\n#          rain_total_pred \u003d predict(base_rain_model,\n#                                    newdata \u003d base_train)\n#          )"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_list \u003c- list(\n  track_min_dist \u003d base_track_model,\n  wind_max \u003d base_wind_model,\n  rain_total \u003d base_rain_model,\n  roof_strong_wall_strong \u003d base_roof_strong_wall_strong_model,\n  roof_strong_wall_light \u003d base_roof_strong_wall_light_model,\n  roof_strong_wall_salv \u003d base_roof_strong_wall_salv_model,\n  roof_light_wall_strong \u003d base_roof_light_wall_strong_model,\n  roof_light_wall_light \u003d base_roof_light_wall_light_model,\n  roof_light_wall_salv \u003d base_roof_light_wall_salv_model,\n  roof_salv_wall_strong \u003d base_roof_salv_wall_strong_model,\n  roof_salv_wall_light \u003d base_roof_salv_wall_light_model,\n  roof_salv_wall_salv \u003d base_roof_salv_wall_salv_model\n)\n\n# Apply predictions efficiently\ndf_base_train2 \u003c- df_base_train2 %\u003e%\n  mutate(across(names(model_list), ~ predict(model_list[[cur_column()]], newdata \u003d df_base_train2), .names \u003d \"{.col}_pred\")) \n\n# Define wind and rain interaction variables\nwind_fractions \u003c- c(\"blue_ss_frac\", \"yellow_ss_frac\", \"orange_ss_frac\", \"red_ss_frac\")\nrain_fractions \u003c- c(\"blue_ls_frac\", \"yellow_ls_frac\", \"orange_ls_frac\", \"red_ls_frac\")\n\n# Compute wind interaction terms dynamically\ndf_base_train2 \u003c- df_base_train2 %\u003e%\n  mutate(across(all_of(wind_fractions), ~ . * wind_max_pred, .names \u003d \"wind_{.col}\"),\n         across(all_of(rain_fractions), ~ . * rain_total_pred, .names \u003d \"rain_{.col}\"))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": []
      },
      "source": [
        "# # parameter tuning\n# # Define a grid of hyperparameters\n# cp_values \u003c- seq(0.0001, 0.05, by \u003d 0.0005)\n# maxdepth_values \u003c- c(3, 5, 7, 10)\n# minsplit_values \u003c- c(10, 20, 30, 40)\n# minbucket_values \u003c- c(5, 10, 20)\n\n# # Create an empty list to store results\n# # Create an empty list to store results\n# results \u003c- data.frame(cp \u003d numeric(), maxdepth \u003d numeric(),\n#                       minsplit \u003d numeric(), minbucket \u003d numeric(), RMSE \u003d numeric())\n\n# # predicting for wind and rainfall for the validation dataset\n# df_val_base_tune \u003c- base_validation %\u003e%\n#   mutate(\n#     wind_max_pred \u003d predict(\n#       base_wind_model, newdata \u003d base_validation),\n#     rain_total_pred \u003d predict(\n#       base_rain_model,\n#       newdata \u003d base_validation)\n#     )\n\n# # Train the model using manual grid search\n# grid_id \u003c- 1  # Index for list storage\n\n# # Iterate over all combinations of hyperparameters\n# for (cp in cp_values) {\n#   for (maxdepth in maxdepth_values) {\n#     for (minsplit in minsplit_values) {\n#       for (minbucket in minbucket_values) {\n\n#         # Train the model with specific hyperparameters\n#         model \u003c- rpart(\n#           damage_perc ~ wind_max_pred +\n#             rain_total_pred +\n#             roof_strong_wall_strong +\n#             roof_strong_wall_light +\n#             roof_strong_wall_salv +\n#             roof_light_wall_strong +\n#             roof_light_wall_light +\n#             roof_light_wall_salv +\n#             roof_salv_wall_strong +\n#             roof_salv_wall_light +\n#             roof_salv_wall_salv +\n#             ls_risk_pct +\n#             ss_risk_pct +\n#             wind_blue_ss +\n#             wind_yellow_ss +\n#             wind_orange_ss +\n#             wind_red_ss +\n#             rain_blue_ss +\n#             rain_yellow_ss +\n#             rain_orange_ss +\n#             rain_red_ss,\n#           data \u003d df_base_train,\n#           method \u003d \"anova\",  # Regression\n#           control \u003d rpart.control(cp \u003d cp, maxdepth \u003d maxdepth,\n#                                   minsplit \u003d minsplit, minbucket \u003d minbucket)\n#         )\n\n#         # Make predictions on the validation set\n#         val_predictions \u003c- predict(model, newdata \u003d df_val_base_tune)\n\n#         # Compute RMSE\n#         rmse_value \u003c- rmse(df_val_base_tune$damage_perc, val_predictions)\n\n#         # Store results\n#         results \u003c- rbind(results, data.frame(cp, maxdepth, minsplit, minbucket, RMSE \u003d rmse_value))\n#       }\n#     }\n#   }\n# }\n\n# # Print the best hyperparameter combination\n# best_params \u003c- results[which.min(results$RMSE), ]\n# print(best_params)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define tuning grid\ntune_grid \u003c- expand.grid(\n  nrounds \u003d c(50, 100, 200, 300, 400, 500),\n  max_depth \u003d c(3, 6, 9, 12),\n  eta \u003d c(0.01, 0.05, 0.1, 0.2, 0.3),\n  gamma \u003d c(0, 1, 5, 10),\n  colsample_bytree \u003d c(0.5, 0.7, 0.8, 1.0),\n  min_child_weight \u003d c(1, 3, 5, 10),\n  subsample \u003d c(0.5, 0.7, 0.8, 1.0)\n)\n\n\n# Set up train control with 10-fold cross-validation\ntrain_control \u003c- trainControl(\n  method \u003d \"cv\",\n  number \u003d 10,\n  classProbs \u003d TRUE,  # Needed for AUC calculation\n  summaryFunction \u003d twoClassSummary\n)\n\n# Train the model using grid search with 10-fold CV\nset.seed(1234)\nxgb_model \u003c- train(\n  damage_pred ~ wind_max_pred +\n    rain_total_pred +\n    roof_strong_wall_strong_pred +\n    roof_strong_wall_light_pred +\n    roof_strong_wall_salv_pred +\n    roof_light_wall_strong_pred +\n    roof_light_wall_light_pred +\n    roof_light_wall_salv_pred +\n    roof_salv_wall_strong_pred +\n    roof_salv_wall_light_pred +\n    roof_salv_wall_salv_pred +\n    ls_risk_pct +\n    ss_risk_pct +\n    wind_blue_ss +\n    wind_yellow_ss +\n    wind_orange_ss +\n    wind_red_ss +\n    rain_blue_ss +\n    rain_yellow_ss +\n    rain_orange_ss +\n    rain_red_ss +\n    island_groups +  # Confounder adjustment\n    track_min_dist_pred, # Confounder adjustment\n  data \u003d df_base_train2,\n  method \u003d \"xgbTree\",\n  trControl \u003d train_control,\n  tuneGrid \u003d tune_grid,\n  metric \u003d \"ROC\"  # Optimize based on AUC\n)\n\n# Print best parameters\nprint(xgb_model$bestTune)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training based on tuned parameters\n\n# Combine Training and Validation datasets for final training\n\nfinal_training_df  \u003c- rbind(df_base_train,\n                           df_val_base_tune)\n\n\ndamage_fit_reg_min \u003c- rpart(damage_perc ~ wind_max_pred +\n                              rain_total_pred +\n                              roof_strong_wall_strong +\n                              roof_strong_wall_light +\n                              roof_strong_wall_salv +\n                              roof_light_wall_strong +\n                              roof_light_wall_light +\n                              roof_light_wall_salv +\n                              roof_salv_wall_strong +\n                              roof_salv_wall_light +\n                              roof_salv_wall_salv +\n                              ls_risk_pct +\n                              ss_risk_pct +\n                              wind_blue_ss +\n                              wind_yellow_ss +\n                              wind_orange_ss +\n                              wind_red_ss +\n                              rain_blue_ss +\n                              rain_yellow_ss +\n                              rain_orange_ss +\n                              rain_red_ss,\n                              method \u003d \"anova\",\n                              control \u003d rpart.control(cp \u003d best_params$cp,\n                                                      maxdepth \u003d best_params$maxdepth,\n                                                      minsplit \u003d best_params$minsplit,\n                                                      minbucket \u003d best_params$minbucket),\n                              data \u003d final_training_df\n                         )"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity Check\n# RMSE on the trainset (training + validation)\n# Compute RMSE\n\ndamage_pred  \u003c- predict(damage_fit_reg_min, newdata \u003d final_training_df)\nrmse_value \u003c- rmse(final_training_df$damage_perc, damage_pred)\nrmse_value"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#\u0027 Loggint the model and parameter using MLflow\n# Start MLflow Run\n\n# Configure reticulate to use the Python environment with MLflow\n# use_python(Sys.which(\"python3\"))\n\n# mlflow \u003c- import(\"mlflow\")\n\n# Assuming \u0027damage_fit_class_min\u0027 is your R model object\n# Load your R model (saved as .rds file)\n# model \u003c- readRDS(\"path/to/your/model.rds\")\n\n# Assuming you have some hyperparameters for the model (example)\n#hyperparameters \u003c- list(\n#  cp \u003d best_params$cp,\n#  maxdepth \u003d best_params$maxdepth,\n#  minsplit \u003d best_params$minsplit,\n#  minbucket \u003d best_params$minbucket\n#)\n\n# Assuming \u0027accuracy\u0027 is the accuracy score of your model (example)\n#accuracy \u003c- 0.85  # Replace with your actual accuracy score\n\n# Function to log the R model with hyperparameters and accuracy\n#log_model_to_mlflow \u003c- function(model, accuracy, hyperparameters) {\n    # Start an MLflow run\n#  mlflow$start_run()\n\n  # Log hyperparameters\n#  mlflow$log_param(\"cp\", hyperparameters$cp)\n#  mlflow$log_param(\"maxdepth\", hyperparameters$maxdepth)\n#  mlflow$log_param(\"minsplit\", hyperparameters$minsplit)\n#  mlflow$log_param(\"minbucket\", hyperparameters$minbucket)\n\n\n  # Log model accuracy\n#  mlflow$log_metric(\"accuracy\", accuracy)\n\n  # Save the model to the managed folder path in Dataiku DSS\n#  managed_folder_path \u003c- dkuManagedFolderPath(\"xcPrnvPS\")\n#  model_path \u003c- paste0(managed_folder_path, \"/base_clas_min_model.rds\")\n\n  # Save the model as an RDS file in the managed folder\n#  saveRDS(model, file \u003d model_path)\n\n  # Log the saved model as an artifact in MLflow\n#  mlflow$log_artifact(model_path)\n\n    # End the MLflow run\n#  mlflow$end_run()\n#}\n\n# Log the model, accuracy, and hyperparameters to MLflow\n#log_model_to_mlflow(damage_fit_class_min, accuracy, hyperparameters)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe outputs\nmanaged_folder_path \u003c- dkuManagedFolderPath(\"ZijSaAqQ\")\n\nsaveRDS(damage_fit_reg_min, file \u003d paste0(managed_folder_path, \"/base_reg_min_model.rds\"))\n\nsaveRDS(base_wind_model, file \u003d paste0(managed_folder_path, \"/base_wind_model.rds\"))\n\nsaveRDS(base_rain_model, file \u003d paste0(managed_folder_path, \"/base_rain_model.rds\"))"
      ],
      "outputs": []
    }
  ]
}