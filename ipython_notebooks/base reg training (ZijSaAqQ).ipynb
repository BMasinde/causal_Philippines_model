{
  "metadata": {
    "kernelspec": {
      "name": "r-dku-venv-r_env",
      "display_name": "R (env R_env)",
      "language": "R"
    },
    "hide_input": false,
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "4.4.1"
    },
    "createdOn": 1740392855582,
    "associatedRecipe": "train_base_xgb_reg_ZijSaAqQ",
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740392855582
    },
    "customFields": {},
    "creator": "admin",
    "tags": [
      "recipe-editor"
    ],
    "dkuGit": {
      "lastInteraction": 0
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Libraries\nlibrary(dataiku)\nlibrary(rpart)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(data.table)\nlibrary(mlflow)\nlibrary(reticulate)\nlibrary(Metrics)\nlibrary(purrr)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe inputs\nbase_train \u003c- dkuReadDataset(\"base_train\", samplingMethod\u003d\"head\", nbRows\u003d100000)\nbase_validation \u003c- dkuReadDataset(\"base_validation\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Combining train and validation datasets to one\n# Because we are going to use CV to train the models later\n# naming it df_base_train2 to remain consistent with df naming\ndf_base_train2  \u003c- rbind(base_train, base_validation)\n\ncat(\"number of rows in combined train data:\", nrow(df_base_train2), sep \u003d \" \")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training track_min_dist ~ island_groups\n# we will need to also include island_groups\n# in the final outcome prediction model to adjust for the confounding\n\nbase_track_model  \u003c- rpart(track_min_dist  ~ island_groups,\n                          data \u003d df_base_train2,\n                          method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training structural equation for wind speed\n# wind_speed \u003d f(track_min_dist, eps)\n\nbase_wind_model \u003c- rpart(wind_max ~ track_min_dist,\n                       data \u003d df_base_train2,\n                       method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training structural equation for rain speed\n# rain_total \u003d f(track_min_dist, eps)\n\nbase_rain_model \u003c- rpart(rain_total ~ track_min_dist,\n                       data \u003d df_base_train2,\n                       method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Building typologies are determined by region\nbase_roof_strong_wall_strong_model  \u003c- rpart(roof_strong_wall_strong  ~ island_groups, \n                                             data \u003d df_base_train2,\n                                            method \u003d \"anova\")\n\nbase_roof_strong_wall_light_model  \u003c- rpart(roof_strong_wall_light ~ island_groups,\n                                           data \u003d df_base_train2,\n                                           method \u003d \"anova\")\n\nbase_roof_strong_wall_salv_model  \u003c- rpart(roof_strong_wall_salv ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\nbase_roof_light_wall_strong_model  \u003c- rpart(roof_light_wall_strong ~ island_groups,\n                                           data \u003d df_base_train2,\n                                           method \u003d \"anova\")\nbase_roof_light_wall_light_model  \u003c- rpart(roof_light_wall_light ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\nbase_roof_light_wall_salv_model  \u003c- rpart(roof_light_wall_salv ~ island_groups,\n                                         data \u003d df_base_train2,\n                                         method \u003d \"anova\")\n\nbase_roof_salv_wall_strong_model  \u003c- rpart(roof_salv_wall_strong ~ island_groups,\n                                          data \u003d df_base_train2,\n                                          method \u003d \"anova\")\n\nbase_roof_salv_wall_light_model  \u003c- rpart(roof_salv_wall_light ~ island_groups,\n                                  data \u003d df_base_train2,\n                                  method \u003d \"anova\")\n\nbase_roof_salv_wall_salv_model  \u003c- rpart(roof_salv_wall_salv ~ island_groups,\n                                  data \u003d df_base_train2,\n                                  method \u003d \"anova\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ]
      },
      "source": [
        "# # Adding the predicted parents\u0027 to the training dataset\n\n# df_base_train \u003c- base_train %\u003e%\n#   mutate(wind_max_pred \u003d predict(base_wind_model,\n#                                  newdata \u003d df_base_train2),\n#          rain_total_pred \u003d predict(base_rain_model,\n#                                    newdata \u003d base_train)\n#          )"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_list \u003c- list(\n  track_min_dist \u003d base_track_model,\n  wind_max \u003d base_wind_model,\n  rain_total \u003d base_rain_model,\n  roof_strong_wall_strong \u003d base_roof_strong_wall_strong_model,\n  roof_strong_wall_light \u003d base_roof_strong_wall_light_model,\n  roof_strong_wall_salv \u003d base_roof_strong_wall_salv_model,\n  roof_light_wall_strong \u003d base_roof_light_wall_strong_model,\n  roof_light_wall_light \u003d base_roof_light_wall_light_model,\n  roof_light_wall_salv \u003d base_roof_light_wall_salv_model,\n  roof_salv_wall_strong \u003d base_roof_salv_wall_strong_model,\n  roof_salv_wall_light \u003d base_roof_salv_wall_light_model,\n  roof_salv_wall_salv \u003d base_roof_salv_wall_salv_model\n)\n\n# Apply predictions efficiently\ndf_base_train2 \u003c- df_base_train2 %\u003e%\n  mutate(across(names(model_list), ~ predict(model_list[[cur_column()]], newdata \u003d df_base_train2), .names \u003d \"{.col}_pred\")) \n\n# Define wind and rain interaction variables\nwind_fractions \u003c- c(\"blue_ss_frac\", \"yellow_ss_frac\", \"orange_ss_frac\", \"red_ss_frac\")\nrain_fractions \u003c- c(\"blue_ls_frac\", \"yellow_ls_frac\", \"orange_ls_frac\", \"red_ls_frac\")\n\n# Compute wind interaction terms dynamically\ndf_base_train2 \u003c- df_base_train2 %\u003e%\n  mutate(across(all_of(wind_fractions), ~ . * wind_max_pred, .names \u003d \"wind_{.col}\"),\n         across(all_of(rain_fractions), ~ . * rain_total_pred, .names \u003d \"rain_{.col}\"))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ]
      },
      "source": [
        "# # parameter tuning\n# # Define a grid of hyperparameters\n# cp_values \u003c- seq(0.0001, 0.05, by \u003d 0.0005)\n# maxdepth_values \u003c- c(3, 5, 7, 10)\n# minsplit_values \u003c- c(10, 20, 30, 40)\n# minbucket_values \u003c- c(5, 10, 20)\n\n# # Create an empty list to store results\n# # Create an empty list to store results\n# results \u003c- data.frame(cp \u003d numeric(), maxdepth \u003d numeric(),\n#                       minsplit \u003d numeric(), minbucket \u003d numeric(), RMSE \u003d numeric())\n\n# # predicting for wind and rainfall for the validation dataset\n# df_val_base_tune \u003c- base_validation %\u003e%\n#   mutate(\n#     wind_max_pred \u003d predict(\n#       base_wind_model, newdata \u003d base_validation),\n#     rain_total_pred \u003d predict(\n#       base_rain_model,\n#       newdata \u003d base_validation)\n#     )\n\n# # Train the model using manual grid search\n# grid_id \u003c- 1  # Index for list storage\n\n# # Iterate over all combinations of hyperparameters\n# for (cp in cp_values) {\n#   for (maxdepth in maxdepth_values) {\n#     for (minsplit in minsplit_values) {\n#       for (minbucket in minbucket_values) {\n\n#         # Train the model with specific hyperparameters\n#         model \u003c- rpart(\n#           damage_perc ~ wind_max_pred +\n#             rain_total_pred +\n#             roof_strong_wall_strong +\n#             roof_strong_wall_light +\n#             roof_strong_wall_salv +\n#             roof_light_wall_strong +\n#             roof_light_wall_light +\n#             roof_light_wall_salv +\n#             roof_salv_wall_strong +\n#             roof_salv_wall_light +\n#             roof_salv_wall_salv +\n#             ls_risk_pct +\n#             ss_risk_pct +\n#             wind_blue_ss +\n#             wind_yellow_ss +\n#             wind_orange_ss +\n#             wind_red_ss +\n#             rain_blue_ss +\n#             rain_yellow_ss +\n#             rain_orange_ss +\n#             rain_red_ss,\n#           data \u003d df_base_train,\n#           method \u003d \"anova\",  # Regression\n#           control \u003d rpart.control(cp \u003d cp, maxdepth \u003d maxdepth,\n#                                   minsplit \u003d minsplit, minbucket \u003d minbucket)\n#         )\n\n#         # Make predictions on the validation set\n#         val_predictions \u003c- predict(model, newdata \u003d df_val_base_tune)\n\n#         # Compute RMSE\n#         rmse_value \u003c- rmse(df_val_base_tune$damage_perc, val_predictions)\n\n#         # Store results\n#         results \u003c- rbind(results, data.frame(cp, maxdepth, minsplit, minbucket, RMSE \u003d rmse_value))\n#       }\n#     }\n#   }\n# }\n\n# # Print the best hyperparameter combination\n# best_params \u003c- results[which.min(results$RMSE), ]\n# print(best_params)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define tuning grid\ntune_grid \u003c- expand.grid(\n  nrounds \u003d c(50, 100, 150),\n  max_depth \u003d c(3, 6, 9),\n  eta \u003d c(0.1, 0.2),\n  gamma \u003d c(0, 0.01, 1),\n  colsample_bytree \u003d c(0.7, 1.0),\n  min_child_weight \u003d c(1, 3),\n  subsample \u003d c(0.7, 1.0)\n)\n\n\n# Set up train control with 10-fold cross-validation\ntrain_control \u003c- trainControl(\n  method \u003d \"cv\",\n  number \u003d 3,\n  summaryFunction \u003d defaultSummary\n)\n\n# Train the model using grid search with 3-fold CV\nset.seed(1234)\nbase_xgb_reg_model \u003c- train(\n  damage_perc ~ wind_max_pred +\n    rain_total_pred +\n    roof_strong_wall_strong_pred +\n    roof_strong_wall_light_pred +\n    roof_strong_wall_salv_pred +\n    roof_light_wall_strong_pred +\n    roof_light_wall_light_pred +\n    roof_light_wall_salv_pred +\n    roof_salv_wall_strong_pred +\n    roof_salv_wall_light_pred +\n    roof_salv_wall_salv_pred +\n    ls_risk_pct +\n    ss_risk_pct +\n    wind_blue_ss +\n    wind_yellow_ss +\n    wind_orange_ss +\n    wind_red_ss +\n    rain_blue_ss +\n    rain_yellow_ss +\n    rain_orange_ss +\n    rain_red_ss +\n    island_groups +  # Confounder adjustment\n    track_min_dist_pred, # Confounder adjustment\n  data \u003d df_base_train2,\n  method \u003d \"xgbTree\",\n  trControl \u003d train_control,\n  tuneGrid \u003d tune_grid,\n  metric \u003d \"RMSE\"  # Optimize based on AUC\n)\n\n# Print best parameters\nprint(base_xgb_model$bestTune)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ]
      },
      "source": [
        "# # Training based on tuned parameters\n\n# # Combine Training and Validation datasets for final training\n\n# final_training_df  \u003c- rbind(df_base_train,\n#                            df_val_base_tune)\n\n\n# damage_fit_reg_min \u003c- rpart(damage_perc ~ wind_max_pred +\n#                               rain_total_pred +\n#                               roof_strong_wall_strong +\n#                               roof_strong_wall_light +\n#                               roof_strong_wall_salv +\n#                               roof_light_wall_strong +\n#                               roof_light_wall_light +\n#                               roof_light_wall_salv +\n#                               roof_salv_wall_strong +\n#                               roof_salv_wall_light +\n#                               roof_salv_wall_salv +\n#                               ls_risk_pct +\n#                               ss_risk_pct +\n#                               wind_blue_ss +\n#                               wind_yellow_ss +\n#                               wind_orange_ss +\n#                               wind_red_ss +\n#                               rain_blue_ss +\n#                               rain_yellow_ss +\n#                               rain_orange_ss +\n#                               rain_red_ss,\n#                               method \u003d \"anova\",\n#                               control \u003d rpart.control(cp \u003d best_params$cp,\n#                                                       maxdepth \u003d best_params$maxdepth,\n#                                                       minsplit \u003d best_params$minsplit,\n#                                                       minbucket \u003d best_params$minbucket),\n#                               data \u003d final_training_df\n#                          )"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ----------------------       Logging model performanc using MLFLOW ------------------\n\n# set tracking URI\nmlflow_set_tracking_uri(\"http://127.0.0.1:5000\")\n\n# Ensure any active run is ended\nsuppressWarnings(try(mlflow_end_run(), silent \u003d TRUE))\n\n# Logging metrics for model training and the parameters used\nmlflow_set_experiment(experiment_name \u003d \"SCM - XGBOOST base regression - CV (Training metircs)\")\n\n# Ensure that MLflow has only one run. Start MLflow run once.\nrun_name \u003c- paste(\"XGBoost Run\", Sys.time())  # Unique name using current time\n\n\n# Start MLflow run\nmlflow_start_run(nested \u003d FALSE)\n\n# Ensure the run ends even if an error occurs\n#on.exit(mlflow_end_run(), add \u003d TRUE)\n\n\n# -------- best parameters ---------------\nbest_params \u003c- base_xgb_reg_model$bestTune\n\n# Log each of the best parameters in MLflow\nfor (param in names(best_params)) {\n  mlflow_log_param(param, best_params[[param]])\n}\n\n# ---------- train using best parameters\ndamage_fit_reg_min \u003c- train(damage_perc ~ wind_max_pred +\n                              rain_total_pred +\n                              roof_strong_wall_strong_pred +\n                              roof_strong_wall_light_pred +\n                              roof_strong_wall_salv_pred +\n                              roof_light_wall_strong_pred +\n                              roof_light_wall_light_pred +\n                              roof_light_wall_salv_pred +\n                              roof_salv_wall_strong_pred +\n                              roof_salv_wall_light_pred +\n                              roof_salv_wall_salv_pred +\n                              ls_risk_pct +\n                              ss_risk_pct +\n                              wind_blue_ss +\n                              wind_yellow_ss +\n                              wind_orange_ss +\n                              wind_red_ss +\n                              rain_blue_ss +\n                              rain_yellow_ss +\n                              rain_orange_ss +\n                              rain_red_ss +\n                              island_groups +  # Confounder adjustment\n                              track_min_dist_pred, # Confounder adjustment\n                              method \u003d \"xgbTree\",\n                              trControl \u003d trainControl(method \u003d \"none\"),\n                              tuneGrid \u003d best_params, # Use the best parameters here\n                              metric \u003d \"RMSE\", \n                              data \u003d df_base_train2\n                         )\n\n# obtain predicted values\ntrain_predictions \u003c- damage_fit_reg_min$pred$pred\n\n\n# Define bin edges\n# Define bin edges\nbins \u003c- c(0.00009, 1, 10, 50, 100)\n\n# Assign data to bins\nbin_labels \u003c- cut(df_base_train2$damage_perc, breaks \u003d bins, include.lowest \u003d TRUE, right \u003d TRUE)\n\n# Create a data frame with actual, predicted, and bin labels\ndata \u003c- data.frame(\n  actual \u003d df_base_train2$damage_perc,\n  predicted \u003d train_predictions,\n  bin \u003d bin_labels\n)\n\n# Calculate RMSE per bin\nunique_bins \u003c- levels(data$bin) # Get unique bin labels\nrmse_by_bin \u003c- data.frame(bin \u003d unique_bins, rmse \u003d NA, count \u003d NA) # Initialize results data frame\n\nfor (i in seq_along(unique_bins)) {\n  bin_data \u003c- data[data$bin \u003d\u003d unique_bins[i], ] # Filter data for the current bin\n  rmse_by_bin$rmse[i] \u003c- sqrt(mean((bin_data$actual - bin_data$predicted)^2, na.rm \u003d TRUE)) # Calculate RMSE\n  rmse_by_bin$count[i] \u003c- nrow(bin_data) # Count observations in the bin\n}\n\n# Display RMSE by bin\nprint(rmse_by_bin)\n\n# Log binned RMSE metrics  \nmlflow_log_metric(\"RMSE_0.00009_1]\", rmse_by_bin[1, 1])\nmlflow_log_metric(\"RMSE_1_10]\", rmse_by_bin[2, 1])\nmlflow_log_metric(\"RMSE_10_50]\", rmse_by_bin[3, 1])\nmlflow_log_metric(\"RMSE_50_100]\", rmse_by_bin[4, 1])\n\n# End MLflow run\nmlflow_end_run()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity Check\n# RMSE on the trainset (training + validation)\n# Compute RMSE\n\ndamage_pred  \u003c- predict(damage_fit_reg_min, newdata \u003d df_base_train2)\nrmse_value \u003c- rmse(final_training_df$damage_perc, damage_pred)\nrmse_value"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe outputs\nmanaged_folder_path \u003c- dkuManagedFolderPath(\"ZijSaAqQ\")\n\n# ------------ Models in a list -----------------------\nmodels \u003c- list(damage_fit_reg_min,\n               base_wind_model, \n               base_rain_model, \n               base_track_model,\n               base_roof_strong_wall_strong_model,\n               base_roof_strong_wall_light_model,\n               base_roof_strong_wall_salv_model,\n               base_roof_light_wall_strong_model,\n               base_roof_light_wall_light_model,\n               base_roof_light_wall_salv_model, \n               base_roof_salv_wall_strong_model,\n               base_roof_salv_wall_light_model,\n               base_roof_salv_wall_salv_model\n              )\nmodel_names \u003c- c(\"base_reg_min_model\",\n                 \"base_wind_model\", \n                 \"base_rain_model\", \n                 \"base_track_model\",\n                 \"base_roof_strong_wall_strong_model\",\n                 \"base_roof_strong_wall_light_model\",\n                 \"base_roof_strong_wall_salv_model\",\n                 \"base_roof_light_wall_strong_model\",\n                 \"base_roof_light_wall_light_model\",\n                 \"base_roof_light_wall_salv_model\", \n                 \"base_roof_salv_wall_strong_model\",\n                 \"base_roof_salv_wall_light_model\",\n                 \"base_roof_salv_wall_salv_model\"\n                )\n\n#----------------------- Saving trained XGBOOST model ----------------------------------------\nmapply(function(model, name) {\n  saveRDS(model, file \u003d paste0(managed_folder_path, \"/\", name, \".rds\"))\n}, models, model_names)\n\n\n# saveRDS(damage_fit_reg_min, file \u003d paste0(managed_folder_path, \"/base_reg_min_model.rds\"))\n\n# saveRDS(base_wind_model, file \u003d paste0(managed_folder_path, \"/base_wind_model.rds\"))\n\n# saveRDS(base_rain_model, file \u003d paste0(managed_folder_path, \"/base_rain_model.rds\"))"
      ],
      "outputs": []
    }
  ]
}