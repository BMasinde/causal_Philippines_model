{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R (env R_env)",
      "language": "R",
      "name": "r-dku-venv-r_env"
    },
    "associatedRecipe": "compute_xcPrnvPS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740376599429
    },
    "creator": "admin",
    "createdOn": 1740376599429,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {}
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Libraries\n",
        "library(dataiku)\n",
        "library(rpart)\n",
        "library(dplyr)\n",
        "library(caret)\n",
        "library(pROC) # For AUC calculation\n",
        "library(data.table)\n",
        "library(mlflow)\n",
        "library(reticulate)\n",
        "library(Matrix)\n",
        "library(purrr) # useful for code optimization\n",
        "library(themis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe inputs\n",
        "df_base_train \u003c- dkuReadDataset(\"base_train\", samplingMethod\u003d\"head\", nbRows\u003d100000)\n",
        "df_base_validation \u003c- dkuReadDataset(\"base_validation\", samplingMethod\u003d\"head\", nbRows\u003d100000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Combining train and validation datasets to one\n",
        "# Because we are going to use CV to train the models later\n",
        "# naming it df_base_train2 to remain consistent with df naming\n",
        "df_base_train2  \u003c- rbind(df_base_train, df_base_validation)\n",
        "\n",
        "cat(\"number of rows in combined train data:\", nrow(df_base_train2), sep \u003d \" \")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training track_min_dist ~ island_groups\n",
        "# we will need to also include island_groups\n",
        "# in the final outcome prediction model to adjust for the confounding\n",
        "\n",
        "base_track_model  \u003c- rpart(track_min_dist  ~ island_groups,\n",
        "                          data \u003d df_base_train2,\n",
        "                          method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training structural equation for wind speed\n",
        "# wind_speed \u003d f(track_min_dist, eps)\n",
        "\n",
        "\n",
        "base_wind_model \u003c- rpart(wind_max ~ track_min_dist,\n",
        "                       data \u003d df_base_train2,\n",
        "                       method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training structural equation for rain speed\n",
        "# rain_total \u003d f(track_min_dist, eps)\n",
        "\n",
        "base_rain_model \u003c- rpart(rain_total ~ track_min_dist,\n",
        "                       data \u003d df_base_train2,\n",
        "                       method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Building typologies are determined by region\n",
        "base_roof_strong_wall_strong_model  \u003c- rpart(roof_strong_wall_strong  ~ island_groups,\n",
        "                                             data \u003d df_base_train2,\n",
        "                                            method \u003d \"anova\")\n",
        "\n",
        "base_roof_strong_wall_light_model  \u003c- rpart(roof_strong_wall_light ~ island_groups,\n",
        "                                           data \u003d df_base_train2,\n",
        "                                           method \u003d \"anova\")\n",
        "\n",
        "base_roof_strong_wall_salv_model  \u003c- rpart(roof_strong_wall_salv ~ island_groups,\n",
        "                                          data \u003d df_base_train2,\n",
        "                                          method \u003d \"anova\")\n",
        "base_roof_light_wall_strong_model  \u003c- rpart(roof_light_wall_strong ~ island_groups,\n",
        "                                           data \u003d df_base_train2,\n",
        "                                           method \u003d \"anova\")\n",
        "base_roof_light_wall_light_model  \u003c- rpart(roof_light_wall_light ~ island_groups,\n",
        "                                          data \u003d df_base_train2,\n",
        "                                          method \u003d \"anova\")\n",
        "base_roof_light_wall_salv_model  \u003c- rpart(roof_light_wall_salv ~ island_groups,\n",
        "                                         data \u003d df_base_train2,\n",
        "                                         method \u003d \"anova\")\n",
        "\n",
        "base_roof_salv_wall_strong_model  \u003c- rpart(roof_salv_wall_strong ~ island_groups,\n",
        "                                          data \u003d df_base_train2,\n",
        "                                          method \u003d \"anova\")\n",
        "\n",
        "base_roof_salv_wall_light_model  \u003c- rpart(roof_salv_wall_light ~ island_groups,\n",
        "                                  data \u003d df_base_train2,\n",
        "                                  method \u003d \"anova\")\n",
        "\n",
        "base_roof_salv_wall_salv_model  \u003c- rpart(roof_salv_wall_salv ~ island_groups,\n",
        "                                  data \u003d df_base_train2,\n",
        "                                  method \u003d \"anova\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# OPTMIZED CODE\n",
        "# Define models in a named list\n",
        "model_list \u003c- list(\n",
        "  track_min_dist \u003d base_track_model,\n",
        "  wind_max \u003d base_wind_model,\n",
        "  rain_total \u003d base_rain_model,\n",
        "  roof_strong_wall_strong \u003d base_roof_strong_wall_strong_model,\n",
        "  roof_strong_wall_light \u003d base_roof_strong_wall_light_model,\n",
        "  roof_strong_wall_salv \u003d base_roof_strong_wall_salv_model,\n",
        "  roof_light_wall_strong \u003d base_roof_light_wall_strong_model,\n",
        "  roof_light_wall_light \u003d base_roof_light_wall_light_model,\n",
        "  roof_light_wall_salv \u003d base_roof_light_wall_salv_model,\n",
        "  roof_salv_wall_strong \u003d base_roof_salv_wall_strong_model,\n",
        "  roof_salv_wall_light \u003d base_roof_salv_wall_light_model,\n",
        "  roof_salv_wall_salv \u003d base_roof_salv_wall_salv_model\n",
        ")\n",
        "\n",
        "# Apply predictions efficiently\n",
        "df_base_train2 \u003c- df_base_train2 %\u003e%\n",
        "  mutate(across(names(model_list), ~ predict(model_list[[cur_column()]], newdata \u003d df_base_train2), .names \u003d \"{.col}_pred\"))\n",
        "\n",
        "# Define wind and rain interaction variables\n",
        "wind_fractions \u003c- c(\"blue_ss_frac\", \"yellow_ss_frac\", \"orange_ss_frac\", \"red_ss_frac\")\n",
        "rain_fractions \u003c- c(\"blue_ls_frac\", \"yellow_ls_frac\", \"orange_ls_frac\", \"red_ls_frac\")\n",
        "\n",
        "# Compute wind interaction terms dynamically\n",
        "df_base_train2 \u003c- df_base_train2 %\u003e%\n",
        "  mutate(across(all_of(wind_fractions), ~ . * wind_max_pred, .names \u003d \"wind_{.col}\"),\n",
        "         across(all_of(rain_fractions), ~ . * rain_total_pred, .names \u003d \"rain_{.col}\"))\n",
        "# ------------------------------- OLD MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Adding the predicted parents\u0027 to the training dataset\n",
        "\n",
        "# df_train \u003c- df_train %\u003e%\n",
        "#   mutate(track_min_dist_pred \u003d predict(base_track_model, newdata \u003d df_base_train2), # predicted min_dist\n",
        "#          wind_max_pred \u003d predict(base_wind_model, newdata \u003d df_base_train2),\n",
        "#          rain_total_pred \u003d predict(base_rain_model, newdata \u003d df_base_train2),\n",
        "#          #---- Updating interaction terms ------------------------\n",
        "#          wind_blue_ss \u003d wind_max_pred * blue_ss_frac,\n",
        "#          wind_yellow_ss \u003d wind_max_pred * yellow_ss_frac,\n",
        "#          wind_orange_ss \u003d wind_max_pred * orange_ss_frac,\n",
        "#          wind_red_ss \u003d wind_max_pred * red_ss_frac,\n",
        "#          rain_blue_ss \u003d rain_total_pred * blue_ls_frac,\n",
        "#          rain_yellow_ss \u003d rain_total_pred * yellow_ls_frac,\n",
        "#          rain_orange_ss \u003d rain_total_pred * orange_ls_frac,\n",
        "#          rain_red_ss \u003d rain_total_pred * red_ls_frac,\n",
        "#          # -------- Updating building typologies ------------------\n",
        "#          roof_strong_wall_strong_pred \u003d predict(base_roof_strong_wall_strong_model, newdata \u003d df_base_train2),\n",
        "#          roof_strong_wall_light_pred \u003d predict(base_roof_strong_wall_light_model, newdata \u003d df_base_train2),\n",
        "#          roof_strong_wall_salv_pred \u003d predict(base_roof_strong_wall_salv_model, newdata \u003d df_base_train2),\n",
        "#          roof_light_wall_strong_pred \u003d predict(base_roof_light_wall_strong_model, newdata \u003d df_base_train2),\n",
        "#          roof_light_wall_light_pred \u003d predict(base_roof_light_wall_light_model, newdata \u003d df_base_train2),\n",
        "#          roof_light_wall_salv_pred \u003d predict(base_roof_light_wall_salv_model, newdata \u003d df_base_train2),\n",
        "#          roof_salv_wall_strong_pred \u003d predict(base_roof_salv_wall_strong_model, newdata \u003d df_base_train2),\n",
        "#          roof_salv_wall_light_pred \u003d predict(base_roof_salv_wall_light_model, newdata \u003d df_base_train2),\n",
        "#          roof_salv_wall_salv_pred \u003d predict(base_roof_salv_wall_salv_model, newdata \u003d df_base_train2),\n",
        "#          )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "#--------------------------- NOT NEEDED BECAUSE WE OPT TO DO CV IN TRAINING -------------------------------------\n",
        "# Adding the predicted parents\u0027 to the validation dataset\n",
        "# predicting for wind and rainfall for the validation dataset\n",
        "#df_base_validation \u003c- df_base_validation %\u003e%\n",
        "#  mutate(track_min_dist_pred \u003d predict(base_track_model, newdata \u003d df_base_validation),  # First predict for track_min_dist from regions\n",
        "#    wind_max_pred \u003d predict(base_wind_model, newdata \u003d df_base_validation),\n",
        "#    rain_total_pred \u003d predict(base_rain_model, newdata \u003d df_base_validation),\n",
        "#    wind_blue_ss \u003d wind_max_pred * blue_ss_frac,\n",
        "#    wind_yellow_ss \u003d wind_max_pred * yellow_ss_frac,\n",
        "#    wind_orange_ss \u003d wind_max_pred * orange_ss_frac,\n",
        "#    wind_red_ss \u003d wind_max_pred * red_ss_frac,\n",
        "#    rain_blue_ss \u003d rain_total_pred * blue_ls_frac,\n",
        "#    rain_yellow_ss \u003d rain_total_pred * yellow_ls_frac,\n",
        "#    rain_orange_ss \u003d rain_total_pred * orange_ls_frac,\n",
        "#    rain_red_ss \u003d rain_total_pred * red_ls_frac,\n",
        "#  )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# ------------------ GRID SEARCH TUNING ------------------------------------\n",
        "# # Parameter tuning\n",
        "\n",
        "# # Define tuning grid\n",
        "# tune_grid \u003c- expand.grid(\n",
        "#   nrounds \u003d c(50, 100, 150),       # Number of boosting rounds\n",
        "#   max_depth \u003d c(3, 6, 9),          # Maximum tree depth\n",
        "#   eta \u003d c(0.01, 0.1, 0.3),         # Learning rate\n",
        "#   gamma \u003d 0,                       # Minimum loss reduction\n",
        "#   colsample_bytree \u003d 0.8,          # Feature selection rate\n",
        "#   min_child_weight \u003d 1,            # Minimum instance weight\n",
        "#   subsample \u003d 0.8                  # Sample ratio per boosting round\n",
        "# )\n",
        "\n",
        "\n",
        "# # Create an empty list to store results\n",
        "# results_list \u003c- list()\n",
        "\n",
        "# # Extra data prep\n",
        "# # Ensure target variable is a factor for classification\n",
        "# df_base_train2$damage_binary \u003c- as.factor(df_base_train2$damage_binary)\n",
        "# #df_base_validation$damage_binary \u003c- as.factor(df_base_validation$damage_binary)\n",
        "\n",
        "# # Train the model using manual grid search\n",
        "# grid_id \u003c- 1  # Index for list storage\n",
        "\n",
        "# # Iterate over all combinations of hyperparameters\n",
        "# for (i in 1:nrow(tune_grid)) {\n",
        "#   params \u003c- tune_grid[i, ]\n",
        "\n",
        "#         # setting seed for reproducibility\n",
        "#         set.seed(1234)\n",
        "#         # Train the model with specific hyperparameters\n",
        "#         xgb_model \u003c- train(\n",
        "#           as.factor(damage_binary) ~ wind_max_pred +\n",
        "#             rain_total_pred +\n",
        "#             roof_strong_wall_strong +\n",
        "#             roof_strong_wall_light +\n",
        "#             roof_strong_wall_salv +\n",
        "#             roof_light_wall_strong +\n",
        "#             roof_light_wall_light +\n",
        "#             roof_light_wall_salv +\n",
        "#             roof_salv_wall_strong +\n",
        "#             roof_salv_wall_light +\n",
        "#             roof_salv_wall_salv +\n",
        "#             ls_risk_pct +\n",
        "#             ss_risk_pct +\n",
        "#             wind_blue_ss +\n",
        "#             wind_yellow_ss +\n",
        "#             wind_orange_ss +\n",
        "#             wind_red_ss +\n",
        "#             rain_blue_ss +\n",
        "#             rain_yellow_ss +\n",
        "#             rain_orange_ss +\n",
        "#             rain_red_ss +\n",
        "#             island_groups, # CONFOUNDER ADJUSTED\n",
        "#           data \u003d df_base_train,\n",
        "#           method \u003d \"xgbTree\", # XGBoost method\n",
        "#           trControl \u003d trainControl(method \u003d \"none\"),  # No automatic validation\n",
        "#           tuneGrid \u003d params # Hyperparameter grid\n",
        "#         )\n",
        "\n",
        "#         # Make probability predictions for classification\n",
        "#         val_predictions \u003c- predict(xgb_model, newdata \u003d df_base_validation, type \u003d \"prob\")[,2]  # Probability of class 1\n",
        "\n",
        "#         # Compute AUC (better for classification)\n",
        "#         auc_value \u003c- auc(df_base_validation$damage_binary, val_predictions)\n",
        "\n",
        "#         # Store results efficiently in a list\n",
        "#         results_list[[i]] \u003c- data.frame(params, AUC \u003d auc_value)\n",
        "# }\n",
        "\n",
        "# # Convert list to data frame\n",
        "# results \u003c- rbindlist(results_list)\n",
        "\n",
        "# # Print the best hyperparameter combination (highest AUC)\n",
        "# best_params \u003c- results[which.max(results$AUC), ]\n",
        "# print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Ensure target variable is a factor\n",
        "# Ensure the target variable is a factor with valid names\n",
        "\n",
        "#df_base_train2$damage_binary \u003c- as.factor(df_base_train2$damage_binary)\n",
        "\n",
        "# -------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "df_base_train2$damage_binary_2 \u003c- factor(df_base_train2$damage_binary,\n",
        "                                       levels \u003d c(\"0\", \"1\"),  # Your current levels\n",
        "                                       labels \u003d c(\"Damage_below_10\", \"Damage_above_10\"))  # New valid labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# ---------------------- CLASSIFICATION MDOEL TRAINING WITH 10 CV \u0026 GRID SEARCH PARAMETER TUNING -----------------\n",
        "# Define tuning grid\n",
        "# tune_grid \u003c- expand.grid(\n",
        "#   nrounds \u003d c(50, 100, 200, 300, 400, 500),\n",
        "#   max_depth \u003d c(3, 6, 9, 12),\n",
        "#   eta \u003d c(0.01, 0.05, 0.1, 0.2, 0.3),\n",
        "#   gamma \u003d c(0, 1, 5, 10),\n",
        "#   colsample_bytree \u003d c(0.5, 0.7, 0.8, 1.0),\n",
        "#   min_child_weight \u003d c(1, 3, 5, 10),\n",
        "#   subsample \u003d c(0.5, 0.7, 0.8, 1.0)\n",
        "# )\n",
        "\n",
        "tune_grid \u003c- expand.grid(\n",
        "  nrounds \u003d c(50, 100, 200),\n",
        "  max_depth \u003d c(3, 6),\n",
        "  eta \u003d c(0.1, 0.2),\n",
        "  gamma \u003d c(0, 1),\n",
        "  colsample_bytree \u003d c(0.7, 1.0),\n",
        "  min_child_weight \u003d c(1, 3),\n",
        "  subsample \u003d c(0.7, 1.0)\n",
        ")\n",
        "\n",
        "\n",
        "# Set up train control with 10-fold cross-validation\n",
        "train_control \u003c- trainControl(\n",
        "  method \u003d \"cv\",\n",
        "  number \u003d 3,\n",
        "  classProbs \u003d TRUE,  # Needed for AUC calculation\n",
        "  summaryFunction \u003d twoClassSummary,\n",
        "  sampling \u003d \"smote\" # caret automatically identifies minority class\n",
        ")\n",
        "\n",
        "# Measure the time for a code block to run\n",
        "system.time({\n",
        "    # Train the model using grid search with 10-fold CV\n",
        "    set.seed(1234)\n",
        "    xgb_model \u003c- train(\n",
        "      damage_binary_2 ~ wind_max_pred +\n",
        "        rain_total_pred +\n",
        "        roof_strong_wall_strong_pred +\n",
        "        roof_strong_wall_light_pred +\n",
        "        roof_strong_wall_salv_pred +\n",
        "        roof_light_wall_strong_pred +\n",
        "        roof_light_wall_light_pred +\n",
        "        roof_light_wall_salv_pred +\n",
        "        roof_salv_wall_strong_pred +\n",
        "        roof_salv_wall_light_pred +\n",
        "        roof_salv_wall_salv_pred +\n",
        "        ls_risk_pct +\n",
        "        ss_risk_pct +\n",
        "        wind_blue_ss +\n",
        "        wind_yellow_ss +\n",
        "        wind_orange_ss +\n",
        "        wind_red_ss +\n",
        "        rain_blue_ss +\n",
        "        rain_yellow_ss +\n",
        "        rain_orange_ss +\n",
        "        rain_red_ss +\n",
        "        island_groups +  # Confounder adjustment\n",
        "        track_min_dist_pred, # Confounder adjustment\n",
        "        data \u003d df_base_train2,\n",
        "        method \u003d \"xgbTree\",\n",
        "        trControl \u003d train_control,\n",
        "        tuneGrid \u003d tune_grid,\n",
        "        metric \u003d \"ROC\", # Optimize based on AUC\n",
        "        sample \u003d \"smote\"\n",
        "    )\n",
        "    Sys.sleep(2)  # This is just an example to simulate a delay\n",
        "})\n",
        "\n",
        "# Print best parameters\n",
        "print(xgb_model$bestTune)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "xgb_model$bestTune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Training based on tuned parameters\n",
        "\n",
        "# Combine Training and Validation datasets for final training\n",
        "\n",
        "#final_training_df  \u003c- rbind(df_base_train,\n",
        "#                           df_base_validation)\n",
        "\n",
        "\n",
        "# Extract the best parameters (remove AUC column)\n",
        "best_params_model \u003c- xgb_model$bestTune\n",
        "\n",
        "damage_fit_class_full \u003c- train(\n",
        "          damage_binary_2 ~ wind_max_pred +\n",
        "            rain_total_pred +\n",
        "            roof_strong_wall_strong_pred +\n",
        "            roof_strong_wall_light_pred +\n",
        "            roof_strong_wall_salv_pred +\n",
        "            roof_light_wall_strong_pred +\n",
        "            roof_light_wall_light_pred +\n",
        "            roof_light_wall_salv_pred +\n",
        "            roof_salv_wall_strong_pred +\n",
        "            roof_salv_wall_light_pred +\n",
        "            roof_salv_wall_salv_pred +\n",
        "            ls_risk_pct +\n",
        "            ss_risk_pct +\n",
        "            wind_blue_ss +\n",
        "            wind_yellow_ss +\n",
        "            wind_orange_ss +\n",
        "            wind_red_ss +\n",
        "            rain_blue_ss +\n",
        "            rain_yellow_ss +\n",
        "            rain_orange_ss +\n",
        "            rain_red_ss +\n",
        "            island_groups +  # Confounder adjustment\n",
        "           track_min_dist_pred, # Confounder adjustment\n",
        "          data \u003d df_base_train2, # USE TRAINING AND VALIDATION SETS COMBINED\n",
        "          method \u003d \"xgbTree\", # XGBoost method\n",
        "          trControl \u003d trainControl(method \u003d \"none\"),  # No automatic validation\n",
        "          tuneGrid \u003d best_params_model # USE BEST PARAMETER\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Sanity Check\n",
        "# testing on the training datasets (training + validation)\n",
        "\n",
        "## Outcome prediction on the final_training_df dataset\n",
        "## default function predict returns class probabilities (has two columns)\n",
        "y_pred \u003c- predict(damage_fit_class_full,\n",
        "                  newdata \u003d df_base_train2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "levels(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# using table function\n",
        "conf_matrix \u003c- confusionMatrix(y_pred,\n",
        "                     df_base_train2$damage_binary_2, # remember to use damage_binary_2\n",
        "                     positive \u003d \"Damage_above_10\"\n",
        "                     )\n",
        "conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "accuracy \u003c- conf_matrix$overall[\u0027Accuracy\u0027]\n",
        "\n",
        "cat(\"test-set accuracy of minimal SCM model:\", accuracy, sep \u003d \" \")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Logging the model and parameter using MLflow\n",
        "\n",
        "# set tracking URI\n",
        "mlflow_set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "\n",
        "# Ensure any active run is ended\n",
        "suppressWarnings(try(mlflow_end_run(), silent \u003d TRUE))\n",
        "\n",
        "# set experiment\n",
        "# Logging metrics for model training and the parameters used\n",
        "mlflow_set_experiment(experiment_name \u003d \"SCM - XGBOOST classification - CV (Training metircs)\")\n",
        "\n",
        "# Ensure that MLflow has only one run. Start MLflow run once.\n",
        "run_name \u003c- paste(\"XGBoost Run\", Sys.time())  # Unique name using current time\n",
        "\n",
        "\n",
        "# Start MLflow run\n",
        "mlflow_start_run(nested \u003d FALSE)\n",
        "\n",
        "# Ensure the run ends even if an error occurs\n",
        "#on.exit(mlflow_end_run(), add \u003d TRUE)\n",
        "\n",
        "# Extract the best parameters (remove AUC column)\n",
        "best_params_model \u003c- xgb_model$bestTune\n",
        "\n",
        "# Log each of the best parameters in MLflow\n",
        "for (param in names(best_params_model)) {\n",
        "  mlflow_log_param(param, best_params_model[[param]])\n",
        "}\n",
        "\n",
        "# Log the model type as a parameter\n",
        "mlflow_log_param(\"model_type\", \"scm-xgboost-classification\")\n",
        "\n",
        "damage_fit_class_full \u003c- train(\n",
        "          damage_binary_2 ~ wind_max_pred +\n",
        "            rain_total_pred +\n",
        "            roof_strong_wall_strong_pred +\n",
        "            roof_strong_wall_light_pred +\n",
        "            roof_strong_wall_salv_pred +\n",
        "            roof_light_wall_strong_pred +\n",
        "            roof_light_wall_light_pred +\n",
        "            roof_light_wall_salv_pred +\n",
        "            roof_salv_wall_strong_pred +\n",
        "            roof_salv_wall_light_pred +\n",
        "            roof_salv_wall_salv_pred +\n",
        "            ls_risk_pct +\n",
        "            ss_risk_pct +\n",
        "            wind_blue_ss +\n",
        "            wind_yellow_ss +\n",
        "            wind_orange_ss +\n",
        "            wind_red_ss +\n",
        "            rain_blue_ss +\n",
        "            rain_yellow_ss +\n",
        "            rain_orange_ss +\n",
        "            rain_red_ss +\n",
        "            island_groups +  # Confounder adjustment\n",
        "           track_min_dist_pred, # Confounder adjustment\n",
        "          data \u003d final_training_df, # USE TRAINING AND VALIDATION SETS COMBINED\n",
        "          method \u003d \"xgbTree\", # XGBoost method\n",
        "          trControl \u003d trainControl(method \u003d \"none\"),  # No automatic validation\n",
        "          tuneGrid \u003d best_params_model # USE BEST PARAMETER\n",
        "        )\n",
        "\n",
        "\n",
        "# summarize results\n",
        "conf_matrix \u003c- confusionMatrix(y_pred,\n",
        "                     final_training_df$damage_binary_2,\n",
        "                     positive \u003d \"Damage_above_10\"\n",
        "                     )\n",
        "\n",
        "# accuracy\n",
        "accuracy  \u003c- conf_matrix$overall[\u0027Accuracy\u0027]\n",
        "\n",
        "# Positive class \u003d 1, precision, recall, and F1\n",
        "# Extract precision, recall, and F1 score\n",
        "precision \u003c- conf_matrix$byClass[\u0027Precision\u0027]\n",
        "recall \u003c- conf_matrix$byClass[\u0027Recall\u0027]\n",
        "f1_score \u003c- conf_matrix$byClass[\u0027F1\u0027]\n",
        "\n",
        "\n",
        "# Log parameters and metrics\n",
        "# mlflow_log_param(\"model_type\", \"scm-xgboost-classification\")\n",
        "mlflow_log_metric(\"accuracy\", accuracy)\n",
        "mlflow_log_metric(\"F1\", f1_score)\n",
        "mlflow_log_metric(\"Precision\", precision)\n",
        "mlflow_log_metric(\"Recall\", recall)\n",
        "\n",
        "\n",
        "# Save model\n",
        "#saveRDS(model, file \u003d file.path(path_2_folder, \"spam_clas_model.rds\"))\n",
        "\n",
        "# End MLflow run\n",
        "mlflow_end_run()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": 0,
      "source": [
        "# Recipe outputs\n",
        "managed_folder_path \u003c- dkuManagedFolderPath(\"xcPrnvPS\")\n",
        "\n",
        "# ------------ Models in a list -----------------------\n",
        "models \u003c- list(damage_fit_class_full,\n",
        "               base_wind_model,\n",
        "               base_rain_model,\n",
        "               base_track_model,\n",
        "               base_roof_strong_wall_strong_model,\n",
        "               base_roof_strong_wall_light_model,\n",
        "               base_roof_strong_wall_salv_model,\n",
        "               base_roof_light_wall_strong_model,\n",
        "               base_roof_light_wall_light_model,\n",
        "               base_roof_light_wall_salv_model,\n",
        "               base_roof_salv_wall_strong_model,\n",
        "               base_roof_salv_wall_light_model,\n",
        "               base_roof_salv_wall_salv_model\n",
        "              )\n",
        "model_names \u003c- c(\"base_clas_full_model\",\n",
        "                 \"base_wind_model\",\n",
        "                 \"base_rain_model\",\n",
        "                 \"base_track_model\",\n",
        "                 \"base_roof_strong_wall_strong_model\",\n",
        "                 \"base_roof_strong_wall_light_model\",\n",
        "                 \"base_roof_strong_wall_salv_model\",\n",
        "                 \"base_roof_light_wall_strong_model\",\n",
        "                 \"base_roof_light_wall_light_model\",\n",
        "                 \"base_roof_light_wall_salv_model\",\n",
        "                 \"base_roof_salv_wall_strong_model\",\n",
        "                 \"base_roof_salv_wall_light_model\",\n",
        "                 \"base_roof_salv_wall_salv_model\"\n",
        "                )\n",
        "\n",
        "#----------------------- Saving trained XGBOOST model ----------------------------------------\n",
        "mapply(function(model, name) {\n",
        "  saveRDS(model, file \u003d paste0(managed_folder_path, \"/\", name, \".rds\"))\n",
        "}, models, model_names)\n",
        "\n",
        "#----------------------- Saving trained XGBOOST model ----------------------------------------\n",
        "#saveRDS(damage_fit_class_full, file \u003d paste0(managed_folder_path, \"/base_clas_full_model.rds\"))\n",
        "\n",
        "#----------------------- Saving parent node models for hazard vars ----------------------------\n",
        "#saveRDS(base_wind_model, file \u003d paste0(managed_folder_path, \"/base_wind_model.rds\"))\n",
        "#saveRDS(base_rain_model, file \u003d paste0(managed_folder_path, \"/base_rain_model.rds\"))\n",
        "#saveRDS(base_track_model, file \u003d paste0(managed_folder_path, \"/base_track_model.rds\"))\n",
        "\n",
        "#----------------------- Saving parent node models for hazard vars -----------------------------"
      ]
    }
  ]
}