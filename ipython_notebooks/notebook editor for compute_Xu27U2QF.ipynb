{
  "metadata": {
    "kernelspec": {
      "name": "r-dku-venv-r_env",
      "display_name": "R (env R_env)",
      "language": "R"
    },
    "hide_input": false,
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "4.4.1"
    },
    "createdOn": 1740387212880,
    "associatedRecipe": "test_predict_xgboost_clas",
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1740387212880
    },
    "customFields": {},
    "creator": "admin",
    "tags": [
      "recipe-editor"
    ],
    "dkuGit": {
      "lastInteraction": 0
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Objective of recipe is to:\n# Predict on the scm_min_clas_model on the test set\n# Get the classification metrics on the test set"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "library(dataiku)\nlibrary(rpart)\nlibrary(caret)\nlibrary(pROC) # For AUC calculation\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(mlflow)\nlibrary(purrr)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ]
      },
      "source": [
        "# predicting track_min_dist, wind_max and rain \u0026 updating the base_test to df_base_test\n\n# df_base_test  \u003c- base_test %\u003e%\n#     mutate(\n#     track_min_dist_pred \u003d predict(base_track_model, newdata \u003d base_test),\n#     wind_max_pred \u003d predict(base_wind_model, newdata \u003d base_test),\n#     rain_total_pred \u003d predict(base_rain_model, newdata \u003d base_test),\n#     wind_blue_ss \u003d wind_max_pred * blue_ss_frac, # Updating interaction terms\n#     wind_yellow_ss \u003d wind_max_pred * yellow_ss_frac,\n#     wind_orange_ss \u003d wind_max_pred * orange_ss_frac,\n#     wind_red_ss \u003d wind_max_pred * red_ss_frac,\n#     rain_blue_ss \u003d rain_total_pred * blue_ls_frac,\n#     rain_yellow_ss \u003d rain_total_pred * yellow_ls_frac,\n#     rain_orange_ss \u003d rain_total_pred * orange_ls_frac,\n#     rain_red_ss \u003d rain_total_pred * red_ls_frac,\n    \n#     )"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe inputs\nfolder_path \u003c- dkuManagedFolderPath(\"xcPrnvPS\")\nbase_test \u003c- dkuReadDataset(\"base_test\", samplingMethod\u003d\"head\", nbRows\u003d100000)\n\n# Define the list of model names\nmodel_names \u003c- c(\"clas_full\",\n                 \"track\",\n                 \"wind\", \n                 \"rain\", \n                 \"track\",\n                 \"roof_strong_wall_strong\",\n                 \"roof_strong_wall_light\",\n                 \"roof_strong_wall_salv\",\n                 \"roof_light_wall_strong\",\n                 \"roof_light_wall_light\",\n                 \"roof_light_wall_salv\",\n                 \"roof_salv_wall_strong\",\n                 \"roof_salv_wall_light\",\n                 \"roof_salv_wall_salv\"\n                )\n\n# Create a named list to store the models\nmodels_list \u003c- list()\n\n# Loop over each model name to construct the file path and read the RDS file\nfor (model_name in model_names) {\n  # Construct the file path for the model\n  file_path \u003c- file.path(folder_path, paste0(\"base_\", model_name, \"_model.rds\"))\n  \n  # Read the model and store it in the list with the model name as the key\n  models_list[[paste0(\"base_\", model_name, \"_model\")]] \u003c- readRDS(file_path)\n}\n\n\n# # Access the models using their names\n# base_clas_full_model  \u003c- models$base_clas_model\n# base_wind_model  \u003c- models$base_wind_model\n# base_rain_model  \u003c- models$base_rain_model\n# base_track_model  \u003c- models$base_track_model\n\n\n\n# # Construct the full file paths for the models\n# clas_file_path \u003c- file.path(folder_path, \"base_clas_full_model.rds\")\n# wind_file_path  \u003c- file.path(folder_path, \"base_wind_model.rds\")\n# rain_file_path  \u003c- file.path(folder_path, \"base_rain_model.rds\")\n# track_file_path  \u003c- file.path(folder_path, \"base_track_model.rds\")\n\n\n# # read the .rds model\n# base_clas_full_model  \u003c- readRDS(clas_file_path)\n# base_wind_model  \u003c- readRDS(wind_file_path)\n# base_rain_model  \u003c- readRDS(rain_file_path)\n# base_track_model  \u003c- readRDS(track_file_path)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply predictions efficiently\n\n# Define models in a named list\ncol_models_list \u003c- list(\n  track_min_dist \u003d models_list[[\"base_track_model\"]],\n  wind_max \u003d models_list[[\"base_wind_model\"]],\n  rain_total \u003d models_list[[\"base_rain_model\"]],\n  roof_strong_wall_strong \u003d models_list[[\"base_roof_strong_wall_strong_model\"]],\n  roof_strong_wall_light \u003d models_list[[\"base_roof_strong_wall_light_model\"]],\n  roof_strong_wall_salv \u003d models_list[[\"base_roof_strong_wall_salv_model\"]],\n  roof_light_wall_strong \u003d models_list[[\"base_roof_light_wall_strong_model\"]],\n  roof_light_wall_light \u003d models_list[[\"base_roof_light_wall_light_model\"]],\n  roof_light_wall_salv \u003d models_list[[\"base_roof_light_wall_salv_model\"]],\n  roof_salv_wall_strong \u003d models_list[[\"base_roof_salv_wall_strong_model\"]],\n  roof_salv_wall_light \u003d models_list[[\"base_roof_salv_wall_light_model\"]],\n  roof_salv_wall_salv \u003d models_list[[\"base_roof_salv_wall_salv_model\"]]\n)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_base_test \u003c-  base_test %\u003e%\n  mutate(across(names(col_models_list), ~ predict(col_models_list[[cur_column()]], \n                                             newdata \u003d base_test), .names \u003d \"{.col}_pred\"))\n\n# Define wind and rain interaction variables\nwind_fractions \u003c- c(\"blue_ss_frac\", \"yellow_ss_frac\", \"orange_ss_frac\", \"red_ss_frac\")\nrain_fractions \u003c- c(\"blue_ls_frac\", \"yellow_ls_frac\", \"orange_ls_frac\", \"red_ls_frac\")\n\n# Compute wind interaction terms dynamically\ndf_base_test \u003c- df_base_test %\u003e%\n  mutate(across(all_of(wind_fractions), ~ . * wind_max_pred, .names \u003d \"wind_{.col}\"),\n         across(all_of(rain_fractions), ~ . * rain_total_pred, .names \u003d \"rain_{.col}\"))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_base_test$damage_binary_2 \u003c- factor(df_base_test2$damage_binary,\n                                       levels \u003d c(\"0\", \"1\"),  # Your current levels\n                                       labels \u003d c(\"Damage_below_10\", \"Damage_above_10\"))  # New valid labels"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# predict for damage_binary\n# Make probability predictions for classification\ny_preds_probs \u003c- predict(models_list[[\"base_clas_full_model\"]], newdata \u003d df_base_test, type \u003d \"prob\")[,2]  # Probability of class 1\n#y_preds_probs"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# AUC\n# Compute AUC (better for classification)\nauc_value \u003c- auc(roc(df_base_test$damage_binary, y_preds_probs))\nauc_value"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# extracting probability that y_pred \u003d\u003d 1\n#y_preds_prob_1 \u003c- y_preds_prob[ ,2]\n\n## assigning final class based on threshold\ny_pred \u003c- ifelse(y_preds_probs \u003e 0.5, 1, 0)\n\n# using table function\nconf_matrix \u003c- confusionMatrix(as.factor(y_pred),\n                     as.factor(df_base_test$damage_binary),\n                     positive \u003d \"1\"\n                     )\nprint(conf_matrix)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "models_list[[\"base_clas_full_model\"]]$bestTune"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# logging in mflow:\n# Logging the model and parameter using MLflow\n\n# set tracking URI\nmlflow_set_tracking_uri(\"http://127.0.0.1:5000\")\n\n# Ensure any active run is ended\nsuppressWarnings(try(mlflow_end_run(), silent \u003d TRUE))\n\n# set experiment\n# Logging metrics for model training and the parameters used\nmlflow_set_experiment(experiment_name \u003d \"SCM - XGBOOST classification -CV (Test metircs)\")\n\n# Ensure that MLflow has only one run. Start MLflow run once.\nrun_name \u003c- paste(\"XGBoost Run\", Sys.time())  # Unique name using current time\n\n\n# Start MLflow run\nmlflow_start_run(nested \u003d FALSE)\n\n# Ensure the run ends even if an error occurs\n#on.exit(mlflow_end_run(), add \u003d TRUE)\n\n# Extract the best parameters (remove AUC column)\n#best_params_model \u003c- best_params %\u003e% # Remove AUC column if present\n#    select(-AUC)\n\nparameters_used  \u003c-models_list[[\"base_clas_full_model\"]]$bestTune\n\n# Log each of the best parameters in MLflow\nfor (param in names(parameters_used)) {\n  mlflow_log_param(param, parameters_used[[param]])\n}\n\n# Log the model type as a parameter\nmlflow_log_param(\"model_type\", \"scm-xgboost-classification\")\n\n# predicting\ny_preds_probs \u003c- predict(base_clas_full_model, newdata \u003d df_base_test, type \u003d \"prob\")[,2]  # Probability of class 1\ny_pred \u003c- ifelse(y_preds_probs \u003e 0.5, 1, 0)\n\n# summarize results\nconf_matrix \u003c- confusionMatrix(as.factor(y_pred),\n                     as.factor(df_base_test$damage_binary),\n                     positive \u003d \"1\"\n                     )\n\n# accuracy\naccuracy  \u003c- conf_matrix$overall[\u0027Accuracy\u0027]\n\n# Positive class \u003d 1, precision, recall, and F1\n# Extract precision, recall, and F1 score\nprecision \u003c- conf_matrix$byClass[\u0027Precision\u0027]\nrecall \u003c- conf_matrix$byClass[\u0027Recall\u0027]\nf1_score \u003c- conf_matrix$byClass[\u0027F1\u0027]\nauc_value \u003c- auc(roc(df_base_test$damage_binary, y_preds_probs))\n\n\n# Log parameters and metrics\n# mlflow_log_param(\"model_type\", \"scm-xgboost-classification\")\nmlflow_log_metric(\"accuracy\", accuracy)\nmlflow_log_metric(\"F1\", f1_score)\nmlflow_log_metric(\"Precision\", precision)\nmlflow_log_metric(\"Recall\", recall)\nmlflow_log_metric(\"AUC\", auc_value)\n\n\n# Save model\n#saveRDS(model, file \u003d file.path(path_2_folder, \"spam_clas_model.rds\"))\n\n# End MLflow run\nmlflow_end_run()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract recall and precision\n# Compute confusion matrix\nconf_matrix \u003c- confusionMatrix(as.factor(y_pred), as.factor(df_base_test$damage_binary), positive \u003d \"1\")\nrecall \u003c- conf_matrix$byClass[\"Sensitivity\"]  # Recall (Sensitivity)\nprecision \u003c- conf_matrix$byClass[\"Precision\"] # Precision\nf1_score  \u003c- conf_matrix$byClass[\"F1\"]\naccuracy  \u003c- conf_matrix$overall[\u0027Accuracy\u0027]\n\n# metrics in a table\n# Create a data frame with the metrics\nmetrics_df \u003c- data.frame(\n  Metric \u003d c(\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"),\n  Value \u003d c(accuracy, recall, precision, f1_score, auc_value)\n)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "metrics_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recipe outputs\nmetrics_folder_path \u003c- dkuManagedFolderPath(\"Xu27U2QF\")\n\n# Saving the predicted values\n# Define file path\nfile_path \u003c- file.path(metrics_folder_path, \"model_metrics.csv\")\n\n# Write to CSV\nfwrite(metrics_df, file \u003d file_path, row.names \u003d FALSE)\n\n#dkuWriteDataset(metrics_df, \"min_clas_metrics_df\")\n\n# Print message to confirm\nprint(paste(\"Metrics saved to:\", metrics_folder_path))"
      ],
      "outputs": []
    }
  ]
}